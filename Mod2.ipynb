{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d466d0-2350-4d40-8908-e9960fdd158f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---\n",
    "jupytext:\n",
    "  formats: md:myst\n",
    "  text_representation:\n",
    "    extension: .md\n",
    "    format_name: myst\n",
    "kernelspec:\n",
    "  display_name: Python 3\n",
    "  language: python\n",
    "  name: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450ecd8-b245-4840-a1ce-c68538d24db0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# AI-Powered Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ef5f49-d2b5-4763-9c7e-fea224b1e58e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this notebook, you'll follow a guided walkthrough of how GenAI can be leveraged in the data analysis process. By the end, you'll have an open sandbox where you can experiment in this Python environment with your own AI-generated code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d1d12-5735-4cc1-98a9-b25db73411f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    ":::{attention} `Shift` + `Enter`\n",
    "Remember that you can move forward in the notebook by hitting `Shift` + `Enter`. This is also how you can run code cells. You can also click in a cell and hit the ‚ñ∂Ô∏è button at the top of the notebook to run code in a cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7c603-86e6-462d-9bc0-fa9b9369edba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Learning to Think Step-by-Step in Data Analysis\n",
    "\n",
    "The main thing I want you to learn is to tackle data analysis in a, well, analytical way, breaking down the data analysis process into a clear step-by-step process:\n",
    "\n",
    "1. **Contextualize:** Identify your context. What data are you working with? What's the general topic of what you're trying to do? This initial context is crucial for framing your analysis.\n",
    "\n",
    "2. **Set a Goal:** What is your general goal? What do you want to achieve with this data analysis? Having a clear objective is key.\n",
    "\n",
    "3. **Strategize:** With that goal in mind, what's a good strategy for getting there? What tools do you want to use? What approaches or methods? What order do you need to do things in? Planning your approach ensures better outcomes.\n",
    "\n",
    "4. **Implement:** A carefully articulated strategy should help you in this main process that implements your tools and methods. Many people skip to this step without doing the work beforehand!\n",
    "\n",
    "5. **Interact:** This is the iterative process of data analysis. You will need to interpret your results, troubleshoot if things aren't going your way, or iterate to get a more refined version of what you want.\n",
    "\n",
    "6. **Document:** Once you've got what you want, make sure you record‚Äîin detail‚Äîwhat you did to get there! This is important both for sharing data and for revisiting your analyses later yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5865a08-8ab1-467b-9165-b4379734ed4d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The Role of AI in Data Analysis\n",
    "\n",
    "How you interact with AI in the context of data analysis will depend on the AI tools you're using, the data, and your experience, among other factors. A useful way to direct your interactions is to consider different roles that AI can take on in this process. These roles roughly correspond to a mode of interaction and your comfort and experience level with the specific data analysis process you want to engage in.\n",
    "\n",
    "| Role       | Mode       | Level       |\n",
    "|:----------:|:----------:|:-----------:|\n",
    "| Tutor      | Learning   | Novice      |\n",
    "| Co-pilot   | Exploring  | Intermediate|\n",
    "| Intern     | Producing  | Expert      |\n",
    "\n",
    "Take these levels with a grain of salt because you might be experienced or advanced in some areas of data analysis but want to engage with AI as a tutor to learn a new analysis or use a new package.\n",
    "\n",
    "In the walkthrough, you'll see tabs for these different roles/modes of engaging with AI at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48398902-5ec7-459e-bee4-e582d2bc9d4b",
   "metadata": {},
   "source": [
    "# Step 1: Contextualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434bc9e-a58b-466e-a7af-8b6e0262f77c",
   "metadata": {},
   "source": [
    "## Set up your GenAI tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a563b348-2394-4743-a63d-b7165c0c39fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "It's important to set up whatever your tool is with the context of your dataset and what you'll be engaging in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5303eb-9aa5-4c0d-a93a-380f605a517e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Tutor (Learning Mode)\n",
    ":sync: tab-tutor-contextualize\n",
    "```\n",
    "Act as a Data Analysis Tutor to provide a strong educational foundation for my data analysis project.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "1. Educate: Explain each step and decision clearly.\n",
    "2. Guide: Use the provided CSV file for illustrations and answering questions.\n",
    "3. Respond Patiently: Answer queries with clear, instructive insights, waiting for my cues.\n",
    "4. Review: Discuss errors or misconceptions post-evaluation.\n",
    "5. Confirm: Paraphrase my instructions to ensure alignment.\n",
    "\n",
    "Working Environment: Jupyter Notebook.\n",
    "\n",
    "Paraphrase my instructions to verify your comprehension.\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{tab-item} Co-pilot (Exploring Mode)\n",
    ":sync: tab-copilot-contextualize\n",
    "```\n",
    "Serve as a Data Analysis Copilot to navigate my data analysis project.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "1. Collaborate: Understand data nuances influencing our analysis.\n",
    "2. Integrate: Use the provided CSV file in our workspace for discussions.\n",
    "3. Dialogue: Engage in a two-way interaction, pausing for my input.\n",
    "4. Review: Jointly assess results, considering improvements.\n",
    "5. Confirm: Echo my directives to ensure synchronization.\n",
    "\n",
    "Working Environment: Jupyter Notebook.\n",
    "\n",
    "Echo my objectives back to confirm alignment.\n",
    "\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{tab-item} Intern (Producing Mode)\n",
    ":sync: tab-intern-contextualize\n",
    "```\n",
    "Function as a Data Analysis Intern, executing tasks I delegate.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "1. Query: Request details influencing task outcomes.\n",
    "2. Execute: Load and apply the provided CSV file as instructed.\n",
    "3. Conform: Follow instructions strictly, without introducing new steps.\n",
    "4. Feedback: Confirm if steps align with objectives post-execution.\n",
    "5. Repeat: Echo my instructions to demonstrate adherence.\n",
    "\n",
    "Working Environment: Jupyter Notebook.\n",
    "\n",
    "Retell my commands to confirm accurate following.\n",
    "```\n",
    ":::\n",
    "\n",
    "And, yes, these were generated and iterated with AI!\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f042e19-31c2-4cf0-a780-18d6cf9abb28",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    ":::{attention} Prompts are not magic or universal\n",
    ":class: dropdown\n",
    "\n",
    "These suggested prompts are a _starting point_, but you'll have to actually put some thought into what makes sense for you to include in your prompt:\n",
    "- How big is your context window? (i.e. how much text can you put in there)\n",
    "- Does your tool have a tendency to give verbose (long, wordy) replies?\n",
    "- Can you access other settings like the systems prompt etc?\n",
    "\n",
    "**There are no magic words that will reliably get you a perfect result from an AI chatbot**. Even when you do find something close to a \"perfect prompt\", it may stop working after the model is updated or some other aspect of the tool's design is changed.\n",
    "\n",
    "Any of these will affect the best way to get the most use out of your AI tool. This isn't even covering the fact that many IDE's are now incorporating GenAI into their products, meaning you can often talk to GPT-4, Gemini and other AI model's directly from your notebook.\n",
    "\n",
    "Instead of focusing on optimizing for the current capabilities of the AI tools around you, focus on understanding the _way_ you can delegate and automate aspects of data analysis given the components of that process--i.e. the steps in this exercise!\n",
    "\n",
    "That said, if you're very interested in this topic, there are courses specifically on _prompt engineering_ and there are frequently new academic and media articles that come out with information on the latest prompt engineering insights.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b2750-d1f2-4039-8193-6d6174bd4b47",
   "metadata": {},
   "source": [
    "Depending on your tool of choice, you may not be able to refer to a CSV file or have it run code with that CSV file. Below are some suggested initializing prompts from our readings if you want ideas of what direction to go in for adapting your prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2984d-b21d-46b8-b8f3-82959f3c14b8",
   "metadata": {},
   "source": [
    "::::{note} Adapting context depending on tool capabilities\n",
    ":class: dropdown\n",
    "\n",
    "Below are some example prompts from the Step 0: Context and Setup reading if you need a refresher of what to consider for tool-specific prompting. In particular, whether you can upload files and have access to a cocde interpreter.\n",
    "\n",
    ":::{seealso} Basic (no code interpreter or file upload)\n",
    ":class: dropdown\n",
    "\n",
    "Start the conversation off by specifying your situation and what you‚Äôll be trying to do. I like to prompt with a role I want the GenAI bot to take on.\n",
    "\n",
    "An example of what that initial prompt might look like if you can't upload your data:\n",
    "\n",
    "```\n",
    "Role: Act as a Data Analysis Copilot, providing advice and educational explanations on how to approach my data analysis project.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "Inquire and Clarify: Ask about details that can impact your advice (e.g., data types, dataframe or variable attributes).\n",
    "\n",
    "Contextual Understanding: Use the provided pasted data as context for answering my questions.\n",
    "\n",
    "Here is the data:\n",
    "<data>\n",
    "{paste in some data here,\n",
    "depending on context window,\n",
    "it may only be a few lines}\n",
    "</data>\n",
    "\n",
    "Direct Responses: Answer my questions directly and do not proceed with additional steps until I explicitly ask.\n",
    "\n",
    "Concise and Educational Explanations: Provide concise explanations, discuss the general consensus on different options, and give clear recommendations on how I should proceed, explaining the reasoning behind your advice.\n",
    "\n",
    "Verification Guidance: Provide instructions on how I can verify that the code works and achieves the intended goal.\n",
    "\n",
    "Working Environment: I am using a Jupyter notebook for my work.\n",
    "\n",
    "Repeat back the instructions I have given to ensure understanding.\n",
    "```\n",
    "The last sentence is mainly so that you can separate your first actual query from this role setting stage, and it should give you an idea of how the model is interpreting your instructions. \n",
    "\n",
    "The details of this are beyond the scope of this short course, but you can think of it this way: your input determines your output, and priming the conversation by giving context will influence the output.\n",
    "\n",
    "Feel free to copy this template and adjust as needed.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{seealso} File upload (no code interpreter)\n",
    ":class: dropdown\n",
    "Same as above but you can just say you attached the file instead of pasting it in, you can reference it as an attached file.\n",
    "\n",
    "\n",
    "```\n",
    "Role: Act as a Data Analysis Copilot providing advice and educational explanations on how to approach my data analysis project.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "1. Inquire and Clarify: Ask about details that can impact your advice (e.g., data types, dataframe or variable attributes).\n",
    "    \n",
    "2. Contextual Understanding: Load and use the attached spreadsheet (CSV file) as context for answering my questions.\n",
    "    \n",
    "3. Direct Responses: Answer my questions directly and do not proceed with additional steps until I explicitly ask.\n",
    "    \n",
    "4. Concise and Educational Explanations: Provide concise explanations, discuss the general consensus on different options, and give clear recommendations on how I should proceed, explaining the reasoning behind your advice.\n",
    "    \n",
    "5. Verification Guidance: Provide instructions on how I can verify that the code works and achieves the intended goal.\n",
    "    \n",
    "\n",
    "Working Environment: I am using a Jupyter notebook for my work.\n",
    "\n",
    "Repeat back the instructions I have given to ensure understanding.\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{seealso} Code interpreter\n",
    ":class: dropdown\n",
    "This is in some ways the easiest option because you can have it generate and run code for you to do all the work. However, you‚Äôll still need to ask questions to make sure it has done the task correctly. Some of this can be alleviated by priming it to reflect on its answers at the beginning of the conversation with something like: ‚ÄúAfter running code, revisit my question, critically evaluate your approach, and verify if the output achieved the goal.‚Äù\n",
    "\n",
    "Here‚Äôs what the complete first prompt could look like:\n",
    "\n",
    "```\n",
    "Role: Act as a Data Analysis Copilot providing advice and educational explanations on how to approach my data analysis project.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "1. Inquire and Clarify: Ask about details that can impact your advice (e.g., data types, dataframe or variable attributes).\n",
    "    \n",
    "2. Contextual Understanding: Load and use the attached CSV file as context for answering my questions.\n",
    "    \n",
    "3. Direct Responses: Answer my questions directly and do not proceed with additional steps until I explicitly ask.\n",
    "    \n",
    "4. Critical Evaluation: After running code, revisit my question, critically evaluate your approach, and verify if the output achieved the goal.\n",
    "    \n",
    "5. Instruction Reiteration: Repeat back the instructions I have given to ensure understanding.\n",
    "    \n",
    "\n",
    "Working Environment: I am using a Jupyter notebook for my work.\n",
    "\n",
    "Repeat back the instructions I have given to ensure understanding.\n",
    "```\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def9a955-dde9-4022-99f4-badad790d33c",
   "metadata": {},
   "source": [
    "## Understand what you're working with\n",
    "\n",
    "\n",
    "This is a stage in data analysis where the a user's level really makes a difference in how useful AI can be. All groups can leverage GenAI tools for some combinaton of information retrieval and soundboarding. Even an expert could benefit from this if they're familiar with the subject matter or the types of analysis that are done in a particular field, but maybe they don't know the specific dataset, or at the very least it can help them organize their thoughts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389d50f5-a946-4d74-8aae-424eb3912ba7",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Tutor (Learning Mode)\n",
    ":sync: tab-tutor-contextualize\n",
    "\n",
    "Depending on how unfamiliar you are with the general subject matter and the dataset, you may want to start off very broadly with asking what fields interact and analyze this kind of data, what it is about, what you can learn from it etc. You can ask about how it's formatted and what that means.\n",
    "\n",
    "Example prompt:\n",
    "> I don't know anything about the type of data I'm working with here. Can you tell me more about the subject matter and what is represented in the file?\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Co-pilot (Exploring Mode)\n",
    ":sync: tab-copilot-contextualize\n",
    "\n",
    "You may know a little bit about the data. Maybe you've worked with similar things before and you want to think more creatively. You can use AI to engage in some soundboarding about what is typically done vs. what is cutting edge or what could be an innovative approach.\n",
    "\n",
    "Example prompt: \n",
    "> What kinds of analyses are usually done with this data? And what could be an interesting novel way to look at it?\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Intern (Producing Mode)\n",
    ":sync: tab-intern-contextualize\n",
    "\n",
    "If you're familiar with the type, format, and field of the data, as well as the kinds of analyses that are usually done, this could be a good time to check what your AI-tool knows about this topic as a way to calibrate your expectations. \n",
    "> Tell me what you understand about this data.\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a1b21-651e-434d-9421-c4195584a752",
   "metadata": {},
   "source": [
    ":::::{danger} Understand the limits of AI tools\n",
    "\n",
    "You cannot assume that an AI-chatbot is giving you reliable information. \n",
    "\n",
    "Depending on the tool, you may be dealing with outdated information (end-date of the training data), hallucinations (these may be worse in some models and tools than others), and simplistic or biased materials.\n",
    "\n",
    "**AI tools do not give you a license to stop thinking critically**, in fact, they require even more critical thinking _because_ of how convincing the presentation of the information can be, especially without the context of sources that we can evaluate.\n",
    "\n",
    "Some strategies to consider:\n",
    "- **Browser-Assisted Validation üåê**: Use a tool that has a browser built in and check the sources.\n",
    "- **Retrieval Augmented Verification üîç**: Utilize tools with Retrieval Augmented Generation (RAG) technology and upload a document you trust as the source.\n",
    "\n",
    "Remember, AI tools should be used as a springboard for:\n",
    "- **Orientation üî¶**: They can help steer you in the right direction if you have no idea where to start.\n",
    "- **Clarification üìù**: They can help you break down complex information and provide quick replies to points of confusion.\n",
    "\n",
    "However, you shouldn't use them for:\n",
    "- **Verbatim Acceptance üïµÔ∏è**: Do not accept information at face value.\n",
    "- **Specialized or Debatable Topics üö´**: Sometimes a topic is nuanced and there's no clear \"truth\" and your AI may not reflect that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd24dd5-453b-4ad0-9858-e3d8992ca2d4",
   "metadata": {},
   "source": [
    "# Step 2: Set a Goal\n",
    "\n",
    "What is your general goal? What do you want to achieve with this data analysis? Having a clear objective is key.\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Tutor (Learning Mode)\n",
    ":sync: tab-tutor-setgoal\n",
    "\n",
    "You can use AI to provide a reflection of the common kinds of data analysis that is done in a field. You can then guide your AI to direct you towards the most appropriate analysis for your experience level.\n",
    "\n",
    "Example prompt:\n",
    "> I am deciding on a goal for my data analysis project.\n",
    ">\n",
    "> What kind of research questions do people usually answer with this kind of dataset?\n",
    ">\n",
    "> Indicate what each option would entail and how appropriate it would be for a novice in data analysis and someone who is unfamiliar with this dataset.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Co-pilot (Exploring Mode)\n",
    ":sync: tab-copilot-setgoal\n",
    "\n",
    "You can use AI to reflect on some ideas if you have them. Otherwise, you can just brainstorm some more questions. You can iterate on this step until you find something that piques your interest.\n",
    "\n",
    "Example prompt:\n",
    "> I'm thinking of doing a correlation analysis between the variables in this dataset.\n",
    ">\n",
    "> What could be some more interesting and unconventional analyses I could do in this project?\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Intern (Producing Mode)\n",
    ":sync: tab-intern-setgoal\n",
    "\n",
    "If you're an expert in some type of analysis or very familiar with the dataset, AI may not be particularly useful to you at this stage. If you plan on using it for the rest of the pipeline however, I would simply record your goal and use it as the context for your strategy goal (see below)\n",
    "\n",
    "Example (as first part of next prompt):\n",
    "> My goal is to predict star rating based on available numeric variables and the length of the review.\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "We'll move forward with the goal of predicting star ratings based on numeric variables and review length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec5a36-3f20-4969-956a-566477dbc6aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 3: Strategize\n",
    "\n",
    "With your goal in mind, develop a strategy to achieve it. Consider the tools, methods, and order of operations required to execute your plan effectively.\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Tutor (Learning Mode)\n",
    ":sync: tab-tutor-strategize\n",
    "\n",
    "The best way to strategize is to integrate it with learning about each of the steps. You'll want to iterate through each step to make sure you understand it but you can start with a broad overview and then get into the details. \n",
    "\n",
    "Example prompt:\n",
    "> My goal is to predict star rating based on available numeric variables and the length of the review.\n",
    ">\n",
    "> Help me understand what steps I need to take in my data analysis pipeline to achieve this, as well as what Python libraries I'll need for this.\n",
    "\n",
    "Knowing the basics of data analysis, you'll know that you at least want to see steps on wrangling, (statistical) analysis, and visualization.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Co-pilot (Exploring Mode)\n",
    ":sync: tab-copilot-strategize\n",
    "\n",
    "You can start with the basics and then iterate on alternatives at various steps.   \n",
    "\n",
    "Example prompt:\n",
    "> My goal is to predict star rating based on available numeric variables and the length of the review.\n",
    ">\n",
    "> Provide a basic overview of the necessary steps in the data analysis pipeline.\n",
    ">\n",
    "> Include different approaches and relevant Python packages for each step, highlighting their pros and cons.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Intern (Producing Mode)\n",
    ":sync: tab-intern-strategize\n",
    "\n",
    "Starting with the context you articulated from your goal, you can now check in and iterate on all the steps you want to go through to build your data analysis pipeline. You can either iterate, or immediately give guidance about how much detail you want in the strategy.\n",
    "\n",
    "Example prompt:\n",
    "> My goal is to predict star rating based on available numeric variables and the length of the review.\n",
    ">\n",
    "> Provide an overview of the necessary steps in the data analysis pipeline, including statistical methods, visualizations, and relevant Python libraries.\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "Take time to make sure you're aligned on the strategy. Some AI tools can be a bit overzealous in answering your questions. They may skip directly to implementing _one_ of the things they suggested, but you're in charge: make sure *you* are making the decisions about what to do because you will be responsible for your choices and you will need to explain them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db8f3a-2e9f-432a-914a-6b793e20ed82",
   "metadata": {},
   "source": [
    "# Step 4: Implement\n",
    "\n",
    "It's tempting to get to this point and say \"AI, do the thing!\" and walk away. To be honest, it may work. And as tools improve, it may well be possible to do this. \n",
    "\n",
    "However, as of this writing, I can tell you that you'll need to supervise the process a lot more closely. Think of this step as your first draft. \n",
    "\n",
    "You'll need to break things down to implement your data analysis pipeline.\n",
    "\n",
    "Two things that influence how many steps you'll need include: \n",
    "1. Complexity of your strategy\n",
    "2. State of your data\n",
    "\n",
    "If your \"project\" is as simple as \"create a linear regression for predicting X from Y\", you can do that in one go. If your data is pristine and in exactly the right format, some tools may spit out exactly what you need. \n",
    "\n",
    "But, if you're asking for something more complex and/or your data needs some cleaning to get to where you want to go, AI may trip over the basics in an attempt to provide you with what you requested. \n",
    "\n",
    "Break your implementation down into the steps of your data analysis pipeline (based on your strategy) and prompt each step of the way. \n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Tutor (Learning Mode)\n",
    ":sync: tab-tutor-implement\n",
    "\n",
    "You can also use this as an opportunity to learn by asking questions about why AI suggested using a particular approach and what alternatives would be. It can be useful for learning about common (Python) packages as well. \n",
    "\n",
    "Example prompt:\n",
    "> What functions in the scikit-learn package could I use for the regression?\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Co-pilot (Exploring Mode)\n",
    ":sync: tab-copilot-implement\n",
    "\n",
    "There's no need to get experimental directly in the implementation. Unless you feel very confident with the type of analysis _and_ the dataset, it's a good idea to take this as an opportunity to build that first unit test and in the next step you can iterate and explore different options for the analyses or visualizations.\n",
    "\n",
    "Example prompt:\n",
    "> Create a skeleton for a data analysis pipeline that takes our CSV file as input and outputs a PNG file of the model fit plot for the regression.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Intern (Producing Mode)\n",
    ":sync: tab-intern-implement\n",
    "\n",
    "Consider this your first benchmarking step. If you plan on using this particular AI tool, this is the point at which you will find out how much it can do with the context it's been given so far. If your goal is to save time, you can try and prompt it to be reflective (you can look into Chain-of-Thought prompting) and build that first version of the full pipeline. \n",
    "\n",
    "Example prompt:\n",
    "> Using the strategy outlined above, create a data analysis pipeline in Python.\n",
    ">\n",
    "> Break it down into chunks, stating each step and providing the commented code for that step.\n",
    ">\n",
    "> Finally, execute the entire pipeline and display the output.\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112dd0b9-0912-495d-8ce1-68aa01bbb051",
   "metadata": {},
   "source": [
    "# Step 5: Interact\n",
    "\n",
    "Really, the implementation and interaction mode go together. Implementing an AI solution is an iterative process. I think it's more useful to view this step as structured by the nature of your interaction than the level. Here are some ways you might be interacting with your AI:\n",
    "\n",
    "- **Interpretation:** Many AI tools can help you interpret statistical output. This can be text based output from your Python console, but in some cases, AI can also interpret figures! I've found this especially helpful when I'm using a type of plot I don't usually work with. Or if there are many components and it's hard to keep track of what it means together.\n",
    "- **Refining and Scaling:** Once you have a functional pipeline, you can start playing around with the specifics. Do you want your output to be formatted in a particular way? Do you want to run this analysis on multiple files that are similarly formatted?\n",
    "- **Troubleshooting:** Of course, you may run into trouble. Maybe your first draft didn't even work. In this case, you can often try to simply \"regenerate\" (some tools literally have some variant of this with some kind of üîÑ icon). Or, more often, you'll need to ask specific questions and dig into the error outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56722e5c-e78b-42f4-bcc4-dc61838fda7a",
   "metadata": {},
   "source": [
    ":::{error} Beware the doom loop!\n",
    "\n",
    "I speak from experience when I say that I've gone down the AI rabbit hole with troubleshooting before. You may be getting an error and start prompting AI to figure it out. \n",
    "\n",
    "**You need to know when to stop.**\n",
    "\n",
    "There are any number of reasons that it may not be working: \n",
    "- The model doesn't have the necessary knowledge.\n",
    "- Something about your computer's configuration is different than the code interpreter of the AI tool.\n",
    "- The AI tool's code interpreter is down.\n",
    "\n",
    "This is why knowing something about coding and data analysis is useful, even in the age of AI. If you have no idea what's going on, you'll be running the same prompt over and over like your at the slot machines gambling to get the winning prize (output). \n",
    "\n",
    "Some great advice I once got is: **set a time limit**. \n",
    "\n",
    "If you run into a troubleshooting loop, set a time limit (15 mins, 30 mins, etc). And once the time is up, if you haven't figured it out _with_ AI, step away from your computer and the problem. \n",
    "\n",
    "You can come back to it later with fresh eyes and try to figure out what's going on or take on a different strategy.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863fd1e0-5032-470a-a69f-ff99b8b72508",
   "metadata": {},
   "source": [
    "# Step 6: Document\n",
    "As you do your data analysis with your AI tool of choice, remember to document everything!\n",
    "\n",
    "Don't assume AI will remember what _you_ want it to remember. Keep a notebook. This is good practice for data analysis in general, but also important if you want to benchmark the performance of various models. \n",
    "\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Tutor (Learning Mode)\n",
    ":sync: tab-tutor-document\n",
    "\n",
    "You can create a record of what it is that you did each step of the way and use it to review and document your own learning.\n",
    "\n",
    "Example prompt:\n",
    "> Document in detail each step we took in this data analysis project. Make sure all code is well-documented and replicable.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Co-pilot (Exploring Mode)\n",
    ":sync: tab-copilot-document\n",
    "\n",
    "If you experimented with a lot of different approaches, you may want to use this as an opportunity to note, almost like a journal, what did and what didn't work. \n",
    "\n",
    "Example prompt:\n",
    "> Document in detail each step we took in this data analysis project, focusing on the different options we tried and what did and did not work. Make sure all code is well-documented and replicable. \n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Intern (Producing Mode)\n",
    ":sync: tab-intern-document\n",
    "\n",
    "If you're planning to use AI to gain efficiency in processing data at scale, consider using this as a benchmarking exercise. Now that you've gone through this process with this particular tool with this specific configuration, you can see how other tools and models perform and adjust your decisions about what to use in the future. \n",
    "\n",
    "Simply save the prompts (ideally save the conversation as well) with something like:\n",
    "\n",
    "> Repeat back to me all the prompts I've given you in this conversation.\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4311d1-5fb0-4138-aa61-2714bbb9c5c5",
   "metadata": {},
   "source": [
    ":::{tip} Tips for documentation\n",
    "\n",
    "A nice hack I've found is to simply ask the AI to output everything we've done directly as a Jupyter Notebook or Markdown file. To make this process easier, consider:\n",
    "\n",
    "- **Providing directory structure.** If you're loading files, you'll want to make sure the file paths are correct. You can just give that to the AI in the prompt to generate it.\n",
    "\n",
    "- **Outputting as plaintext first.** Sometimes I've had trouble creating the file directly on ChatGPT, so I output as txt in code block, paste and save in a plaintext editor (e.g. TextEdit on MacOS) and change the extension.\n",
    "\n",
    "Example prompt:\n",
    "> Create a Jupyter notebook with a detailed walkthrough of the steps taken to achieve our results. Ensure all code is well-commented for easy replication. Instead of saving the file as a .ipynb, create it in a code block that I can paste into a text file.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9120fc28-e501-44d6-9b4a-a1282bbcf58e",
   "metadata": {},
   "source": [
    "# DIY with AI\n",
    "\n",
    "Your turn! Experiment with the provided datasets in this notebook. Toggle the options below to get code with the correct dataset paths.\n",
    "\n",
    "Alternatively, download the zip file of this lab to use in your own Python environment.\n",
    "\n",
    "Here are a few suggestions about directions to go in with the available datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb386e3-b1db-4b35-bd3c-3fa24166ae7b",
   "metadata": {},
   "source": [
    "  \n",
    ":::{seealso} Play with the Yelp dataset\n",
    ":class: dropdown\n",
    "\n",
    "Paste this code into the code block below to get path to the files.\n",
    "\n",
    "```\n",
    "# Run the setup script (this has helper functions to find the datasets)\n",
    "%run -i ./utils/setup_utils.py\n",
    "output, parent_directory = helpers.get_overview()\n",
    "\n",
    "# Use the search_datasets function with the parent directory\n",
    "search_string = \"Yelp\"  # Example search string\n",
    "dataset_matches = helpers.search_datasets(Path(parent_directory), search_string)\n",
    "\n",
    "# Print the search results\n",
    "helpers.print_search_results(dataset_matches)\n",
    "\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    "If you're looking for something straightforward to test out your skills with, this is a pretty simple dataset we've curated for that purpose.\n",
    "\n",
    "**Suggested direction:** Do a sentiment analysis of the Yelp reviews and create a pie chart of the positive, neutral and negative reviews (we have a subset that we provide as a CSV, learn more about the full dataset [here](https://www.yelp.com/dataset/documentation/main)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ee1ba-c04a-4781-8981-b462c3262024",
   "metadata": {},
   "source": [
    ":::{seealso} Play with the Kaggle datasets\n",
    ":class: dropdown\n",
    "\n",
    "Paste this code into the code block below to get path to the files.\n",
    "\n",
    "```\n",
    "# Run the setup script (this has helper functions to find the datasets)\n",
    "%run -i ./utils/setup_utils.py\n",
    "output, parent_directory = helpers.get_overview()\n",
    "\n",
    "# Use the search_datasets function with the parent directory\n",
    "search_string = \"Kaggle\"  # Example search string\n",
    "dataset_matches = helpers.search_datasets(Path(parent_directory), search_string)\n",
    "\n",
    "# Print the search results\n",
    "helpers.print_search_results(dataset_matches)\n",
    "\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    "For a more intermediate challenge, we have two sizeable datasets from Kaggle.\n",
    "\n",
    "**Suggested direction 1:** Practice data wrangling with the Kaggle dataset `shopping_behavior.csv`, we made it specifically to contain some obvious missing and duplicate data as well as datatype conversion issues (metadata [here](https://www.kaggle.com/datasets/zeesolver/consumer-behavior-and-shopping-habits-dataset)).\n",
    "\n",
    "**Suggested direction 2:**  The `bank_churners.csv` file is another Kaggle dataset (metadata [here](https://www.kaggle.com/datasets/sakshigoyal7/credit-card-customers))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf977897-77dc-4cf1-b568-dee1415c2b21",
   "metadata": {},
   "source": [
    ":::{seealso} Play with the NOAA datasets\n",
    ":class: dropdown\n",
    "\n",
    "Paste this code into the code block below to get path to the files.\n",
    "\n",
    "```\n",
    "# Run the setup script (this has helper functions to find the datasets)\n",
    "%run -i ./utils/setup_utils.py\n",
    "output, parent_directory = helpers.get_overview()\n",
    "\n",
    "# Use the search_datasets function with the parent directory\n",
    "search_string = \"NOAA\"  # Example search string\n",
    "dataset_matches = helpers.search_datasets(Path(parent_directory), search_string)\n",
    "\n",
    "# Print the search results\n",
    "helpers.print_search_results(dataset_matches)\n",
    "\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    "This is one of the more challenging datasets. You'll have to take care to wrangle things properly and reference the metadata to know what each variable means. \n",
    "\n",
    "**Suggested direction:** Merge the NOAA datasets and explore the difference in weather between one Russian and two US locations (metadata in folder `./Datasets/NOAA_Weather`) and [online](https://www.ncei.noaa.gov/data/global-hourly/doc/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c39a4f-46ab-40c2-838e-5a64997dba77",
   "metadata": {},
   "source": [
    "## AI-Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550a7ff-09b2-474a-9b0c-56d30ea77aad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If you want to keep playing around in this environment (i.e. this Notebook), you may want to pass on the context of your setup to your AI, in which case, you can run this code right below to get the necessary information (click `Shift` + `Enter` to run the cell). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacd6936-8530-4474-8793-8b13c1bae454",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this and give it to your AI as context\n",
    "%run -i ./utils/setup_utils.py\n",
    "# Print overview of environment and configuration\n",
    "output, parent_directory = helpers.get_overview()\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856af74f-ef63-4d34-bd1f-1aad4d336564",
   "metadata": {},
   "source": [
    "### Import your data\n",
    "Figure out the relevant filepaths and import the data into this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfbf95d-c6f5-4507-b587-eb6c5c65d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a dataset and copy the code from one of the toggles above and paste it below.\n",
    "# This will tell you where all the relevant data is.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edba3454-bbb4-40b7-8623-3d52bb2d61c1",
   "metadata": {},
   "source": [
    "Now, you can import the data and play around with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e966f5-b47c-41c8-a453-3b04d42378cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b847bbe-1536-4b6d-a4c4-ab743ac3ec9d",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "Use the space below to run your wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620258a-9a39-49a9-ad71-be09dd28f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea56e26-d535-4d6a-ad37-84b77e79c65f",
   "metadata": {},
   "source": [
    "### (Statistical) Analysis \n",
    "A separate cell for you to run any statistical analyses you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57626743-81ca-4ddb-a820-a4894b44664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8483bde5-219d-45e9-bf09-288e856a0d60",
   "metadata": {},
   "source": [
    "### Data Visualization \n",
    "An additional cell for any data visualization you want to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2165f1-174e-4730-84fa-ef237cbb2318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
