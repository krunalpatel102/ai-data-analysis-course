{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1698b99",
   "metadata": {},
   "source": [
    "# Lab 2: Data Wrangling, Analysis, and Visualization\n",
    "\n",
    "## Introduction\n",
    "In this assignment, you will delve into the essential steps of data preprocessing, wrangling, analysis, and visualization. These are crucial techniques in data science to clean, prepare, analyze, and present data effectively. You will be working with three distinct datasets, each presenting unique challenges and learning opportunities.\n",
    "\n",
    "*Again, you are not required to write any code; just run the cells and observe the outputs, except for the 'Reflection Exercise' section at the end.*\n",
    "\n",
    "### Overview of the Lab Topics\n",
    "- **Data Wrangling**: Handling missing values, removing duplicates, converting data types, merging multiple CSV files, and creating new columns\n",
    "- **Data Analysis**: Performing descriptive statistics, correlation analysis, grouping and aggregation, and trend analysis.\n",
    "- **Data Visualization**: Creating various types of plots to visualize the data.\n",
    "\n",
    "This lab will take a while to go through, so don't be afraid to take breaks. And remember to use an AI-copilot as you are going through this to ask questions about bits of code that you don't understand.\n",
    "\n",
    "You can copy the code into your GenAI tool and ask questions like \"Are there other ways of doing this?\" \"Can you explain the pros and cons of using this option?\" \"Can you breakdown this code for me in detail?\"\n",
    "\n",
    "I encourage you to do this to make the most out of the lab! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65190617-4cb0-46cf-be12-61fc8fb06d0e",
   "metadata": {},
   "source": [
    "## 1. Data Wrangling\n",
    "\n",
    "Data wrangling includes preprocessing and cleaning steps that are critical in the data analysis pipeline. The quality of data directly impacts the quality of insights that can be derived from it. Preprocessing involves transforming raw data into a clean and usable format. Cleaning involves handling missing values, correcting errors, and preparing the data for analysis.\n",
    "\n",
    "### Handling Missing Values\n",
    "Missing values are common in datasets and can significantly affect the results of your analysis. Common strategies to handle missing values include:\n",
    "- **Removal**: Removing rows or columns with missing values.\n",
    "- **Imputation**: Filling missing values with a specific value such as the mean, median, or mode of the column.\n",
    "- **Prediction**: Using machine learning models to predict missing values based on other features.\n",
    "\n",
    "Let's start by importing the required libraries and loading the CSV file for `shopping_behavior` dataset in `Kaggle Ecommerce` and examining the data to identify errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92c14ae3-e570-4a9f-b845-af29fa37927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Category</th>\n",
       "      <th>Purchase Amount (USD)</th>\n",
       "      <th>Location</th>\n",
       "      <th>Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Season</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Subscription Status</th>\n",
       "      <th>Shipping Type</th>\n",
       "      <th>Discount Applied</th>\n",
       "      <th>Promo Code Used</th>\n",
       "      <th>Previous Purchases</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Frequency of Purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>53</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>L</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Winter</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Express</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>14</td>\n",
       "      <td>Venmo</td>\n",
       "      <td>Fortnightly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sweater</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>64</td>\n",
       "      <td>Maine</td>\n",
       "      <td>L</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Winter</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Express</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Fortnightly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>73</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>S</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Spring</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Free Shipping</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sandals</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>90</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>M</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Spring</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Next Day Air</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>49</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>49</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>M</td>\n",
       "      <td>Turquoise</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Free Shipping</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>31</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Annually</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer ID  Age Gender Item Purchased  Category Purchase Amount (USD)  \\\n",
       "0            1   55   Male         Blouse  Clothing                    53   \n",
       "1            2   19   Male        Sweater  Clothing                    64   \n",
       "2            3   50   Male          Jeans  Clothing                    73   \n",
       "3            4   21   Male        Sandals  Footwear                    90   \n",
       "4            5   45   Male         Blouse  Clothing                    49   \n",
       "\n",
       "        Location Size      Color  Season Review Rating Subscription Status  \\\n",
       "0       Kentucky    L       Gray  Winter           3.1                 Yes   \n",
       "1          Maine    L     Maroon  Winter           3.1                 Yes   \n",
       "2  Massachusetts    S     Maroon  Spring           3.1                 Yes   \n",
       "3   Rhode Island    M     Maroon  Spring           3.5                 Yes   \n",
       "4         Oregon    M  Turquoise  Spring           2.7                 Yes   \n",
       "\n",
       "   Shipping Type Discount Applied Promo Code Used  Previous Purchases  \\\n",
       "0        Express              Yes             Yes                  14   \n",
       "1        Express              Yes             Yes                   2   \n",
       "2  Free Shipping              Yes             Yes                  23   \n",
       "3   Next Day Air              Yes             Yes                  49   \n",
       "4  Free Shipping              Yes             Yes                  31   \n",
       "\n",
       "  Payment Method Frequency of Purchases  \n",
       "0          Venmo            Fortnightly  \n",
       "1           Cash            Fortnightly  \n",
       "2    Credit Card                 Weekly  \n",
       "3         PayPal                 Weekly  \n",
       "4         PayPal               Annually  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import os  # Module for interacting with the operating system\n",
    "import pandas as pd  # Library for data manipulation and analysis\n",
    "import numpy as np  # Library for numerical computations\n",
    "\n",
    "# Define the relative path to the dataset CSV file\n",
    "file_path = '../Datasets/Kaggle_Ecommerce/shopping_behavior.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "shop_behav = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "shop_behav.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3fdb0-48ce-4999-9406-d3442ccd0b94",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "Identify and handle missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bc2e7a-95ce-44bf-8d94-0cc751091287",
   "metadata": {},
   "source": [
    "This code checks for missing values in the `shop_behav` DataFrame.\n",
    "\n",
    "- **shop_behav.isnull()**: Identifies all the null (missing) values in the DataFrame.\n",
    "- **sum()**: Counts the total number of missing values in each column.\n",
    "\n",
    "The result shows the number of missing values per column, helping us understand the extent of missing data in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73273b0e-a2f1-463c-8023-53a16727ccdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer ID               0\n",
       "Age                       0\n",
       "Gender                    0\n",
       "Item Purchased            0\n",
       "Category                  0\n",
       "Purchase Amount (USD)     1\n",
       "Location                  0\n",
       "Size                      0\n",
       "Color                     2\n",
       "Season                    0\n",
       "Review Rating             1\n",
       "Subscription Status       0\n",
       "Shipping Type             0\n",
       "Discount Applied          0\n",
       "Promo Code Used           0\n",
       "Previous Purchases        0\n",
       "Payment Method            0\n",
       "Frequency of Purchases    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify missing values\n",
    "shop_behav.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c5fed8-956f-4462-bc4b-150da3e65da9",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 10px;\">\n",
    "\n",
    "ðŸ¤– \n",
    "<br>\n",
    "**Now that you know which columns have null values, ask Generative AI about various methods of handling this. Remember to ask about the pros and the cons of different options.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a12323b-86e4-489c-a551-322ce72c3764",
   "metadata": {},
   "source": [
    "This code handles missing values in the `shop_behav` DataFrame. Here, we are filling the missing values with the mean of the corresponding column.\n",
    "\n",
    "- **missing_cols**: Identifies columns with any missing values.\n",
    "- **for col in missing_cols**: Iterates through each column with missing values.\n",
    "    - **if shop_behav[col].dtype in [np.float64, np.int64]**: Checks if the column is numerical.\n",
    "    - **shop_behav[col].fillna(shop_behav[col].mean(), inplace=True)**: Fills missing values in numerical columns with the column mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db61676a-bf39-4df1-afb9-50245effb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with missing values\n",
    "missing_cols = shop_behav.columns[shop_behav.isnull().any()]\n",
    "\n",
    "# Fill missing values in numerical columns with the mean value of those columns\n",
    "for col in missing_cols:\n",
    "    # Check if the column's data type is either float64 or int64 (i.e., a numerical column)\n",
    "    if shop_behav[col].dtype in [np.float64, np.int64]:\n",
    "        # Replace NaN values with the mean of the column\n",
    "        shop_behav[col].fillna(shop_behav[col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d997335f-cfc2-4020-b502-d048adc1550d",
   "metadata": {},
   "source": [
    "We again check for missing values, and as can be seen, there are none left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3a3622c-640c-40e2-94d8-398fd2481b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer ID               0\n",
       "Age                       0\n",
       "Gender                    0\n",
       "Item Purchased            0\n",
       "Category                  0\n",
       "Purchase Amount (USD)     1\n",
       "Location                  0\n",
       "Size                      0\n",
       "Color                     2\n",
       "Season                    0\n",
       "Review Rating             1\n",
       "Subscription Status       0\n",
       "Shipping Type             0\n",
       "Discount Applied          0\n",
       "Promo Code Used           0\n",
       "Previous Purchases        0\n",
       "Payment Method            0\n",
       "Frequency of Purchases    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rechecking for missing values\n",
    "shop_behav.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d381c2-ad94-44c9-9499-cdf098b1a024",
   "metadata": {},
   "source": [
    "### Removing Duplicates\n",
    "Duplicate records can skew your analysis and lead to incorrect insights. Removing duplicates ensures that each record in your dataset is unique. This is typically done by identifying and removing rows that have identical values across all columns.\n",
    "\n",
    "This code checks for duplicate rows in the `shov_behav` DataFrame.\n",
    "\n",
    "- **data2.duplicated()**: Identifies duplicate rows.\n",
    "- **sum()**: Counts the total number of duplicate rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e813005-dd64-4ea7-b404-95d4bd079227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify duplicates\n",
    "shop_behav.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd652bd-8d98-4ade-901b-6ea42ed4d657",
   "metadata": {},
   "source": [
    "This indicates that the dataset has one duplicate row. We will fix it now.\n",
    "\n",
    "- **shop_behav.drop_duplicates(inplace=True)**: Removes duplicate rows from the DataFrame and updates `shop_behav` in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a7002d9-f5f9-479e-964d-4d2022673128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "shop_behav.drop_duplicates(inplace=True)\n",
    "shop_behav.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf72bc9-c2a7-4946-b37d-759eee326a3f",
   "metadata": {},
   "source": [
    "The dataset now has `0` duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae4ba5-fc3b-4eff-9662-a04ef3677e5a",
   "metadata": {},
   "source": [
    "### Data Type Conversion\n",
    "Ensuring that each column has the correct data type is crucial for accurate analysis. In a DataFrame, each column must contain only one type of data. This is because DataFrames are like tables where each column needs to be uniform in type. For example:\n",
    "- Dates should be stored as date objects.\n",
    "- Numbers should be in numerical formats like integers or floats.\n",
    "- Categorical data should be stored as category types.\n",
    "Let's look at an example with the 'Review Rating' column. This column should contain numbers (floats), but due to some rows having extra text like ' stars', its data type is currently a string (object). Here's what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55b6b1a1-b2ab-4b68-b16b-71766b587e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55            3\n",
       "56          4.7\n",
       "57    4.4 stars\n",
       "58          4.2\n",
       "59          4.6\n",
       "Name: Review Rating, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_behav['Review Rating'][55:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b835c3",
   "metadata": {},
   "source": [
    "### Steps to Correct Data Type Conversion\n",
    "\n",
    "1. **Try to Convert the Column to Float**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24e50dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered: could not convert string to float: '4.4 stars'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shop_behav['Review Rating'] = shop_behav['Review Rating'].astype('float')\n",
    "except ValueError as e:\n",
    "    print(f\"Error encountered: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07053e4",
   "metadata": {},
   "source": [
    "- This code tries to change 'Review Rating' to float type.\n",
    "- It fails because some values have ' stars', which can't be converted to a number.\n",
    "- The error message tells us there's a problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. **Find the Problematic Rows**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85d13ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Customer ID  Age Gender Item Purchased   Category Purchase Amount (USD)  \\\n",
      "57           58   21   Male           Coat  Outerwear                    64   \n",
      "\n",
      "         Location Size  Color  Season Review Rating Subscription Status  \\\n",
      "57  West Virginia    M  White  Summer     4.4 stars                 Yes   \n",
      "\n",
      "   Shipping Type Discount Applied Promo Code Used  Previous Purchases  \\\n",
      "57  Store Pickup              Yes             Yes                  17   \n",
      "\n",
      "   Payment Method Frequency of Purchases  \n",
      "57     Debit Card            Fortnightly  \n"
     ]
    }
   ],
   "source": [
    "# Create a function to check if a value can be converted to float\n",
    "def can_convert_to_float(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Apply the function to each value in 'Review Rating' and find problematic rows\n",
    "problematic_rows = shop_behav[~shop_behav['Review Rating'].apply(can_convert_to_float)]\n",
    "print(problematic_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b782763",
   "metadata": {},
   "source": [
    "- This code finds rows where 'Review Rating' has the text 'stars'.\n",
    "- Printing these rows helps us see where the issue is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b7ad5",
   "metadata": {},
   "source": [
    "3. **Clean the 'Review Rating' Column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4edc9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ' stars' from 'Review Rating'\n",
    "shop_behav['Review Rating'] = shop_behav['Review Rating'].str.replace(' stars', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6497e51",
   "metadata": {},
   "source": [
    "- This line removes ' stars' from all values in the 'Review Rating' column.\n",
    "- Now the column should have only numbers as strings, ready to convert to float."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e7ced-b5fe-4256-9300-17d15db9604f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 10px;\">\n",
    "\n",
    "ðŸ¤– \n",
    "<br>\n",
    "**Ask Generative AI the ways you can format these kinds of strings**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecb5e7",
   "metadata": {},
   "source": [
    "\n",
    "4. **Displaying Data Types**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9d01cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer ID                int64\n",
       "Age                        int64\n",
       "Gender                    object\n",
       "Item Purchased            object\n",
       "Category                  object\n",
       "Purchase Amount (USD)     object\n",
       "Location                  object\n",
       "Size                      object\n",
       "Color                     object\n",
       "Season                    object\n",
       "Review Rating             object\n",
       "Subscription Status       object\n",
       "Shipping Type             object\n",
       "Discount Applied          object\n",
       "Promo Code Used           object\n",
       "Previous Purchases         int64\n",
       "Payment Method            object\n",
       "Frequency of Purchases    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_behav.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676ff63",
   "metadata": {},
   "source": [
    "\n",
    "- Displays the data types of all columns in the `shop_behav` DataFrame to verify the conversion. We see that Rating is still an object, so we have to convert it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f2c5a07-0a3c-4631-8f18-af9d77344596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer ID                 int64\n",
       "Age                         int64\n",
       "Gender                     object\n",
       "Item Purchased             object\n",
       "Category                   object\n",
       "Purchase Amount (USD)      object\n",
       "Location                   object\n",
       "Size                       object\n",
       "Color                      object\n",
       "Season                     object\n",
       "Review Rating             float64\n",
       "Subscription Status        object\n",
       "Shipping Type              object\n",
       "Discount Applied           object\n",
       "Promo Code Used            object\n",
       "Previous Purchases          int64\n",
       "Payment Method             object\n",
       "Frequency of Purchases     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixing the 'Review Rating' column by removing the ' stars' string and converting to float\n",
    "shop_behav['Review Rating'] = shop_behav['Review Rating'].str.rstrip(' stars').astype('float') \n",
    "\n",
    "# Display data types of the columns\n",
    "shop_behav.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb4628-72cf-431a-b7fd-814c8c8d1c25",
   "metadata": {},
   "source": [
    "Again checking the same rows of the column, we can see that the data type is now `float64`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20b671eb-13a8-41e5-90a2-7ccd1a03b8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55    3.0\n",
       "56    4.7\n",
       "57    4.4\n",
       "58    4.2\n",
       "59    4.6\n",
       "Name: Review Rating, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_behav['Review Rating'][55:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9ad07",
   "metadata": {},
   "source": [
    "### Merging CSV Files\n",
    "When working with large datasets, data may be split across multiple files. Merging these files into a single dataset is often necessary. This involves reading each file and concatenating them into one dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643fba9-bb49-4ca9-b002-eb19315515e5",
   "metadata": {},
   "source": [
    "We first load the NOAA dataset and list the files it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "933facce-31e5-4804-aac6-f84da087411f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31285099999.csv', '72484653123.csv', '99999926563.csv']\n"
     ]
    }
   ],
   "source": [
    "folder_path = '../Datasets/NOAA_Weather'  # Define the path to the folder containing the CSV files\n",
    "\n",
    "# List comprehension to find all files in the folder that end with '.csv'\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "print(csv_files)  # Print the list of CSV files to check which files were found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42577288-939e-4a0d-89fc-1a3bfe1b6788",
   "metadata": {},
   "source": [
    "We can see that it has three different CSV files, which are basically weather data recordings from three different stations. Let's suppose we want to perform an analysis for all three stations, it is much more efficient to concatenate all of them into one and then perform the required tasks.\n",
    "\n",
    "The below code concatenates multiple CSV files into a single DataFrame.\n",
    "\n",
    "- **pd.concat([...])**: Concatenates the list of DataFrames into a single DataFrame.\n",
    "- **[pd.read_csv(os.path.join(folder_path, file)) for file in csv_files]**: This list comprehension reads each CSV file in the `csv_files` list and returns a list of DataFrames.\n",
    "    - **os.path.join(folder_path, file)**: Constructs the full file path for each CSV file.\n",
    "    - **pd.read_csv(...)**: Reads the CSV file into a DataFrame.\n",
    "- **ignore_index=True**: Ensures that the resulting DataFrame has a new, continuous index.\n",
    "\n",
    "The result is a single DataFrame, `noaa`, containing the data from all the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b2b1b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>CALL_SIGN</th>\n",
       "      <th>QUALITY_CONTROL</th>\n",
       "      <th>...</th>\n",
       "      <th>CU2</th>\n",
       "      <th>CU3</th>\n",
       "      <th>CV1</th>\n",
       "      <th>CV2</th>\n",
       "      <th>CV3</th>\n",
       "      <th>CW1</th>\n",
       "      <th>GH1</th>\n",
       "      <th>IB2</th>\n",
       "      <th>KF1</th>\n",
       "      <th>OB1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T03:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T06:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T09:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T12:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                 DATE SOURCE  LATITUDE   LONGITUDE  ELEVATION  \\\n",
       "0  31285099999  2024-01-01T00:00:00      4      54.5  134.416667       62.0   \n",
       "1  31285099999  2024-01-01T03:00:00      4      54.5  134.416667       62.0   \n",
       "2  31285099999  2024-01-01T06:00:00      4      54.5  134.416667       62.0   \n",
       "3  31285099999  2024-01-01T09:00:00      4      54.5  134.416667       62.0   \n",
       "4  31285099999  2024-01-01T12:00:00      4      54.5  134.416667       62.0   \n",
       "\n",
       "         NAME REPORT_TYPE CALL_SIGN QUALITY_CONTROL  ...  CU2  CU3  CV1  CV2  \\\n",
       "0  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "1  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "2  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "3  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "4  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   CV3  CW1  GH1  IB2  KF1  OB1  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and concatenate all CSV files\n",
    "noaa = pd.concat([pd.read_csv(os.path.join(folder_path, file)) for file in csv_files], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "noaa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8754c91",
   "metadata": {},
   "source": [
    "- `pd.concat([...])` combines multiple DataFrames into a single DataFrame.\n",
    "- `[pd.read_csv(os.path.join(folder_path, file)) for file in csv_files]` reads each CSV file into a DataFrame and creates a list of these DataFrames.\n",
    "- `ignore_index=True` reindexes the combined DataFrame to have a continuous index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f9702a-bd67-47a7-8db0-37dd6e627543",
   "metadata": {},
   "source": [
    "To verify that `noaa` indeed has all three stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91946a62-c9b4-49d8-ab1e-2c877617e028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31285099999, 72484653123, 99999926563])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noaa['STATION'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646b9f2",
   "metadata": {},
   "source": [
    "### Creating New Columns\n",
    "Creating new columns from existing data can provide additional insights or make data analysis easier. This can involve operations like arithmetic transformations, conditional logic, or feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de315e-7842-4b32-a38c-0e9ed1e3d8c4",
   "metadata": {},
   "source": [
    "This code creates a new column 'COORDINATES' in the `noaa` DataFrame by concatenating the 'LATITUDE' and 'LONGITUDE' columns as strings.\n",
    "\n",
    "- **noaa['LATITUDE'].astype('str')**: Converts the 'LATITUDE' column to strings.\n",
    "- **noaa['LONGITUDE'].astype('str')**: Converts the 'LONGITUDE' column to strings.\n",
    "- **noaa['LATITUDE'].astype('str') + ',' + noaa['LONGITUDE'].astype('str')**: Concatenates the latitude and longitude values with a comma in between to form coordinate strings.\n",
    "- **noaa['COORDINATES']**: Assigns the resulting coordinate strings to a new column 'COORDINATES' in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"Coordinates\", which is \"Latitude, Longitude\"\n",
    "noaa['COORDINATES'] = noaa['LATITUDE'].astype('str') + ',' + noaa['LONGITUDE'].astype('str')\n",
    "noaa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23290b5",
   "metadata": {},
   "source": [
    "## 2. Data Analysis\n",
    "\n",
    "In this section, we will perform various data analysis tasks on the Yelp reviews dataset. This includes descriptive statistics, correlation analysis, grouping and aggregation, and trend analysis.\n",
    "\n",
    "Let's first load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3403c04f-0e97-48c7-81d6-ea563290e0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>7/7/2018 22:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>1/3/2012 15:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2/5/2014 20:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>1/4/2015 0:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>1/14/2017 20:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       0      0     0   \n",
       "1      5       1      0     1   \n",
       "2      3       0      0     0   \n",
       "3      5       1      0     1   \n",
       "4      4       1      0     1   \n",
       "\n",
       "                                                text             date  \n",
       "0  If you decide to eat here, just be aware it is...   7/7/2018 22:09  \n",
       "1  I've taken a lot of spin classes over the year...   1/3/2012 15:28  \n",
       "2  Family diner. Had the buffet. Eclectic assortm...   2/5/2014 20:30  \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo...    1/4/2015 0:01  \n",
       "4  Cute interior and owner (?) gave us tour of up...  1/14/2017 20:54  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../Datasets/Yelp_Reviews/reviews.csv'  # Define the path to the CSV file\n",
    "\n",
    "reviews = pd.read_csv(file_path)  # Read the CSV file into a DataFrame\n",
    "\n",
    "reviews.head()  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2074cd-6790-4ee5-8f9d-b6debf966724",
   "metadata": {},
   "source": [
    "### Summary statistics\n",
    "\n",
    "#### Distribution of Ratings\n",
    "We analyze the distribution of ratings in the Yelp reviews dataset. Understanding the distribution of ratings can provide insights into customer satisfaction and help identify patterns or trends in the feedback.\n",
    "\n",
    "- **rating_distribution = reviews['stars'].value_counts().sort_index()**:\n",
    "    - **reviews['stars']**: Select the 'stars' column from the DataFrame `reviews`, which contains the ratings given in the reviews.\n",
    "    - **value_counts()**: Counts the occurrence of each unique rating value, giving us the number of reviews for each rating.\n",
    "    - **sort_index()**: Sorts the counts by the rating values (index) in ascending order.\n",
    "\n",
    "- **rating_distribution**:\n",
    "    - This variable now holds a Series with the count of reviews for each rating, sorted by the rating values. It provides a clear view of how many reviews were given for each rating level (e.g., 1 star, 2 stars, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19062529-59f3-4613-8f2b-450b11057b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "1    226\n",
       "2    151\n",
       "3    240\n",
       "4    483\n",
       "5    900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of Ratings\n",
    "rating_distribution = reviews['stars'].value_counts().sort_index()  # Count the occurrences of each rating and sort by rating value\n",
    "\n",
    "rating_distribution  # Display the distribution of ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e43567",
   "metadata": {},
   "source": [
    "Suggested prompt (remember to paste the output of `head()` from above or upload the file):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00008B; padding: 10px; color: white; padding: 10px;\">\n",
    "\n",
    "ðŸ¤– **Suggested prompt**\n",
    "<br>\n",
    "\n",
    "This is my data:\n",
    "\n",
    "`<data>`\n",
    "\n",
    "{paste data}\n",
    "\n",
    "`</data>`\n",
    "\n",
    "In my lesson, we ran this code:\n",
    "\n",
    "`rating_distribution = reviews['stars'].value_counts().sort_index()  # Count the occurrences of each rating and sort by rating value`\n",
    "\n",
    "Given my dataset, what are some other summary statistics I could look at?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37bc10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste your AI-generated code here to give it a go:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd61d5f",
   "metadata": {},
   "source": [
    "### Statistical Analysis\n",
    "Below are some basic statistical analyses you can do on your dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8bd291-112a-4043-b223-e65b5273e71c",
   "metadata": {},
   "source": [
    "#### Correlation Analysis: Review Length vs Useful Votes\n",
    "Here we analyze the statistical correlation between the length of a review and the number of useful votes it receives. By examining this correlation, we can understand if there is a linear relationship between these two variables.\n",
    "\n",
    "1. Calculate Review Length:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a12547",
   "metadata": {},
   "source": [
    "- **reviews['text']**: Selects the 'text' column from the DataFrame reviews, which contains the review texts.\n",
    "- **apply(len)**: Applies the len function to each review text, calculating the length of each review in terms of the number of characters.\n",
    "- **reviews['review_length']**: Creates a new column 'review_length' in the DataFrame reviews to store the length of each review.\n",
    "\n",
    "2. **Select Relevant Columns**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the relevant columns for correlation analysis\n",
    "review_length_vs_useful = reviews[['review_length', 'useful']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fd11a9",
   "metadata": {},
   "source": [
    "- **reviews[['review_length', 'useful']]**: Selects the 'review_length' and 'useful' columns from the DataFrame `reviews` and creates a new DataFrame `review_length_vs_useful` containing these two columns.\n",
    "\n",
    "3. **Calculate and Display the Correlation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation between review length and useful votes\n",
    "correlation = review_length_vs_useful.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dca1d9",
   "metadata": {},
   "source": [
    "- **review_length_vs_useful.corr()**: Computes the pairwise correlation of columns in the DataFrame `review_length_vs_useful`.\n",
    "- **print(correlation)**: Displays the correlation matrix, showing the correlation coefficient between 'review_length' and 'useful'.\n",
    "\n",
    "The correlation coefficient will provide a measure of how strongly review length and useful votes are related. A coefficient close to 1 indicates a strong positive correlation, close to -1 indicates a strong negative correlation, and close to 0 indicates no correlation.\n",
    "\n",
    "Hereâ€™s the complete code for the correlation analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Review Length\n",
    "reviews['review_length'] = reviews['text'].apply(len)\n",
    "\n",
    "# Select Relevant Columns\n",
    "review_length_vs_useful = reviews[['review_length', 'useful']]\n",
    "\n",
    "# Calculate and Display the Correlation\n",
    "correlation = review_length_vs_useful.corr()\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e384e-877b-4e65-b831-98d057afb8c7",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "We apply sentiment analysis to the review texts to classify them as Positive, Negative, or Neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd36b7e-b776-4776-96b9-3ab8a24e48d6",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 10px;\">\n",
    "\n",
    "ðŸ¤– \n",
    "<br>\n",
    "**Although the explanation of this code block is out of scope for this course, our Generative AI friend can certainly help!**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663f2af-2448-4874-85e5-022d09b4eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to classify sentiment\n",
    "def classify_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis to the text column\n",
    "reviews['sentiment'] = reviews['text'].apply(classify_sentiment)\n",
    "sentiment_distribution = reviews['sentiment'].value_counts()\n",
    "sentiment_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3708d-a2d4-4065-91cf-8799c74ca985",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 10px;\">\n",
    "\n",
    "ðŸ¤– \n",
    "<br>\n",
    "**There are many more types of analysis that can be done on this dataset, it's all just a matter of which questions you want answered! For example- you might want to do sentiment analysis over time, i.e., analyze how the sentiment of reviews has changed over time to identify trends or shifts in customer satisfaction.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c098ce",
   "metadata": {},
   "source": [
    "## 3. Data Visualization\n",
    "\n",
    "In this section, we will create various plots to visualize the data and the results of our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906f45d-5236-4d29-9fed-1750c57ba05d",
   "metadata": {},
   "source": [
    "### Bar Chart for Distribution of Ratings\n",
    "on\n",
    "This plot is a bar chart that visualizes the distribution of star ratings in the Yelp reviews dataset. It shows how frequently each star rating (1 to 5 stars) is given, providing insights into overall customer satisfactiotion\n",
    "\n",
    "- **import matplotlib.pyplot as plt**:\n",
    "    - Imports the `matplotlib.pyplot` module, which is used for creating visualizations.\n",
    "\n",
    "- **plt.figure(figsize=(10, 6))**:\n",
    "    - Creates a new figure with a specified size of 10 inches in width and 6 inches in height.\n",
    "\n",
    "- **reviews['stars'].value_counts().sort_index().plot(kind='bar')**:\n",
    "    - **reviews['stars']**: Selects the 'stars' column from the DataFrame `reviews`.\n",
    "    - **value_counts()**: Counts the occurrence of each unique rating value.\n",
    "    - **sort_index()**: Sorts the counts by the rating values in ascending order.\n",
    "    - **plot(kind='bar')**: Creates a bar plot of the sorted rating counts.\n",
    "\n",
    "- **plt.xlabel('Star Ratings')**:\n",
    "    - Sets the label for the x-axis to 'Star Ratings'.\n",
    "\n",
    "- **plt.ylabel('Frequency')**:\n",
    "    - Sets the label for the y-axis to 'Frequency'.\n",
    "\n",
    "- **plt.title('Distribution of Star Ratings')**:\n",
    "    - Sets the title of the plot to 'Distribution of Star Ratings'.\n",
    "\n",
    "- **plt.show()**:\n",
    "   - Displays the bar chart.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715730d0-b4d4-4204-a952-809d24e00335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar Chart for Distribution of Ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "reviews['stars'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.xlabel('Star Ratings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Star Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f13cf8-4e87-4e42-afea-db7089fbcc2e",
   "metadata": {},
   "source": [
    "### Scatter Plot for Review Length vs Useful Votes\n",
    "\n",
    "This plot is a scatter plot that visualizes the relationship between the length of reviews and the number of useful votes they receive. Each point represents a review, with its position determined by the review's length and the number of useful votes. This helps in identifying any patterns or correlations between these two variables.\n",
    "\n",
    "- **plt.scatter(reviews['review_length'], reviews['useful'], alpha=0.5)**:\n",
    "    - **plt.scatter()**: Creates a scatter plot.\n",
    "    - **reviews['review_length']**: Specifies the x-axis data, which is the length of the reviews.\n",
    "    - **reviews['useful']**: Specifies the y-axis data, which is the number of useful votes.\n",
    "    - **alpha=0.5**: Sets the transparency level of the points to 0.5, making it easier to see overlapping points.\n",
    "\n",
    "- **plt.xlabel('Review Length')**:\n",
    "    - Sets the label for the x-axis to 'Review Length'.\n",
    "\n",
    "- **plt.ylabel('Number of Useful Votes')**:\n",
    "    - Sets the label for the y-axis to 'Number of Useful Votes'.\n",
    "\n",
    "- **plt.title('Review Length vs Useful Votes')**:\n",
    "    - Sets the title of the plot to 'Review Length vs Useful Votes'.\n",
    "\n",
    "- **plt.show()**:\n",
    "    - Displays the scatter plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135a67e-0096-4bce-9fee-577ae7b31a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot for Review Length vs Useful Votes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(reviews['review_length'], reviews['useful'], alpha=0.5)\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Number of Useful Votes')\n",
    "plt.title('Review Length vs Useful Votes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f490e7-d207-4220-b501-802f2cf9addc",
   "metadata": {},
   "source": [
    "### Line Chart for Average Ratings Over Time\n",
    "n\n",
    "This plot is a line chart that visualizes the average star rating of reviews over time. It shows how the average rating has changed monthly, allowing for the identification of trends and patterns in customer satisfaction over the observed perioheight.\n",
    "\n",
    "- **monthly_avg_rating.plot()**:\n",
    "    - Plots the `monthly_avg_rat from the Data Analysis sectioning` Series, which contains the average star rating for each month, as a line chart.\n",
    "\n",
    "- **plt.xlabel('Date')**:\n",
    "    - Sets the label for the x-axis to 'Date'.\n",
    "\n",
    "- **plt.ylabel('Average Star Rating')**:\n",
    "    - Sets the label for the y-axis to 'Average Star Rating'.\n",
    "\n",
    "- **plt.title('Average Star Rating Over Time')**:\n",
    "    - Sets the title of the plot to 'Average Stasplays the line chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f4dbb-1bf0-44c6-bbe6-030455d4d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Chart for Average Ratings Over Time\n",
    "plt.figure(figsize=(10, 6))\n",
    "monthly_avg_rating.plot()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Star Rating')\n",
    "plt.title('Average Star Rating Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5364c4-70fd-46cc-ae5e-620a61fce238",
   "metadata": {},
   "source": [
    "The breaks in the lines indicate that no data was available for these months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb2663-0401-4878-985e-2b69ca590d8c",
   "metadata": {},
   "source": [
    "### Pie Chart for Sentiment Distribution\n",
    "\n",
    "This plot is a pie chart that visualizes the distribution of sentiment classifications (Positive, Negative, Neutral) in the Yelp reviews dataset. It shows the proportion of each sentiment category, providing insights into the overall sentiment of the reviews.\n",
    "\n",
    "- **sentiment_counts = reviews['sentiment'].value_counts()**:\n",
    "    - Counts the occurrences of each sentiment category in the 'sentiment' column of the DataFrame `reviews`, which we created in the Data Analysis section.\n",
    "    - **sentiment_counts**: Stores the counts of each sentiment.\n",
    "\n",
    "- **plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140)**:\n",
    "    - **plt.pie()**: Creates a pie chart.\n",
    "    - **sentiment_counts**: Provides the data for the pie chart (the counts of each sentiment).\n",
    "    - **labels=sentiment_counts.index**: Labels each slice of the pie chart with the sentiment categories.\n",
    "    - **autopct='%1.1f%%'**: Displays the percentage of each slice with one decimal place.\n",
    "    - **startangle=140**: Rotates the start of the pie chart to 140 degrees for better visual presentation.\n",
    "\n",
    "- **plt.title('Sentiment Distribution of Reviews')**:\n",
    "    - Sets the title of the plot to 'Sentiment Distribution of Reviews'.\n",
    "\n",
    "- **plt.show()**:\n",
    "    - Displays the pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff05370-3d31-4b05-a0f6-73e4747187a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart for Sentiment Distribution\n",
    "# Count the occurrences of each sentiment\n",
    "sentiment_counts = reviews['sentiment'].value_counts()\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Sentiment Distribution of Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95caf7-5ecd-469a-b453-86fb230ee179",
   "metadata": {},
   "source": [
    "### Heat Map for Numeric Columns\n",
    "\n",
    "This plot is a heat map that visualizes the correlation between numeric columns in the Yelp reviews dataset. The heat map shows the strength and direction of the relationships between pairs of variables, helping to identify patterns and potential dependencies.\n",
    "\n",
    "- **import seaborn as sns**:\n",
    "    - Imports the `seaborn` library, which is used for creating advanced visualizations.\n",
    "\n",
    "- **numeric_cols = ['stars', 'useful', 'funny', 'cool']**:\n",
    "    - Defines a list of numeric columns that will be included in the heat map.\n",
    "\n",
    "- **corr_matrix = df[numeric_cols].corr()**:\n",
    "    - Computes the correlation matrix for the selected numeric columns.\n",
    "    - **df[numeric_cols]**: Selects the specified numeric columns from the DataFrame `df`.\n",
    "    - **corr()**: Calculates the pairwise correlation coefficients between the columns.\n",
    "\n",
    "- **plt.figure(figsize=(10, 8))**:\n",
    "    - Creates a new figure with a specified size of 10 inches in width and 8 inches in height.\n",
    "\n",
    "- **sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')**:\n",
    "    - **sns.heatmap()**: Plots the heat map.\n",
    "    - **corr_matrix**: Provides the data for the heat map (the correlation matrix).\n",
    "    - **annot=True**: Displays the correlation coefficients on the heat map.\n",
    "    - **cmap='coolwarm'**: Uses the 'coolwarm' colormap for the heat map.\n",
    "    - **fmt='.2f'**: Formats the correlation coefficients to two decimal places.\n",
    "\n",
    "- **plt.title('Correlation Heatmap of Numeric Columns')**:\n",
    "    - Sets the title of the plot to 'Correlation Heatmap of Numeric Columns'.\n",
    "\n",
    "- **plt.show()**:\n",
    "    - Displays the heat map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce50850-7178-4afb-9cb1-4da19e007245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Heat Map for Numeric Columns\n",
    "# Select numeric columns for the heat map\n",
    "numeric_cols = ['stars', 'useful', 'funny', 'cool']\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = reviews[numeric_cols].corr()\n",
    "\n",
    "# Plot the heat map\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap of Numeric Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55d42f7-4a9f-4143-a8d1-3b184c05232d",
   "metadata": {},
   "source": [
    "## 4. Reflection Exercise\n",
    "\n",
    "In this section, you will reflect on your learning experience and answer the following questions. Please provide your answers when prompted by the code.\n",
    "\n",
    "### Questions:\n",
    "\n",
    "1. **What specific data analysis technique or concept did you find most beneficial for your field, and how do you plan to apply it in a practical scenario related to your work or interests?**\n",
    "2. **What was the most challenging aspect of the data analysis techniques you learned in this module, considering your background and experience? How did you overcome this challenge, and what resources or strategies did you find most helpful?**\n",
    "\n",
    "Run the following two cells and input your answers in the text boxes that show up. Don't forget to press `Return` once you are done typing. In case you made a mistake or want to re-enter your answer, just run the corresponding cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc315a-e045-424d-9d96-e631c1e63650",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_insight = input(\"What specific data analysis technique or concept did you find most beneficial for your field, and how do you plan to apply it in a practical scenario related to your work or interests?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49261335-4cc7-4408-a49a-d755876d658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_reflection = input(\"What was the most challenging aspect of the data analysis techniques you learned in this module, considering your background and experience? How did you overcome this challenge, and what resources or strategies did you find most helpful?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c1364-a799-41ba-9412-e09ea856983b",
   "metadata": {},
   "source": [
    "Running the following cell is really important, as this will save the answers you gave above. In case you change your answers to any of the above questions, please be sure to run the following cell again, to save the updated answers.\n",
    "\n",
    "You needn't be too concerned with what this code is really doing, but the crux is it is doing some string operations to convert your answers to a prompt, and then save that to a `.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63283a-d67f-4591-8eee-bb9dc423586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..\\Prompts\\Prompt.txt', 'r') as file:\n",
    "    prompt = file.read()\n",
    "\n",
    "prompt = prompt.replace('***', learning_insight, 1)\n",
    "prompt = prompt.replace('***', challenge_reflection, 1)\n",
    "\n",
    "with open('..\\Prompts\\Prompt.txt', 'w') as file:\n",
    "    file.write(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32af18",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this assignment, you have learned how to build a complete data analysis pipeline:\n",
    "- Preprocess and clean data (handling missing values, removing duplicates, data type conversion).\n",
    "- Wrangle data (merging CSV files, creating new columns).\n",
    "- Perform data analysis (descriptive statistics, correlation analysis, grouping and aggregation, trend analysis, sentiment analysis).\n",
    "- Create data visualizations (bar plots, box plots, scatter plots, line plots, pie charts, heatmaps).\n",
    "\n",
    "These skills are crucial for effective data analysis and will help you in future assignments and real-world data science tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
